Các bước dùng Bert model:
pip install rasa[transformers]
pip install rasa[HFTransformersNLP]

Bo tach tu Tieng Viet

pip install Cython
$ pip install numpy scipy sklearn fasttext python-crfsuite
pip install underthesea
#pip install pyvi
Tạo file vi_tokenizer.py tại đường dẫn D:\Softwares\Conda\envs\tf\Lib\site-packages\rasa\nlu\tokenizers
Nội dung file
import re
from typing import Any, Dict, List, Text
from rasa.nlu.tokenizers.tokenizer import Token, Tokenizer
from rasa.nlu.training_data import Message

from rasa.nlu.constants import TOKENS_NAMES, MESSAGE_ATTRIBUTES
from pyvi import ViTokenizer
class VietnameseTokenizer(Tokenizer):

    provides = [TOKENS_NAMES[attribute] for attribute in MESSAGE_ATTRIBUTES]

    def __init__(self, component_config: Dict[Text, Any] = None) -> None:
        super().__init__(component_config)

    def tokenize(self, message: Message, attribute: Text) -> List[Token]:
        text = message.get(attribute)
        words = ViTokenizer.tokenize(text)

        return self._convert_words_to_tokens(words, text)

Đăng ký tokenizer ở file
 D:\Softwares\Conda\envs\tf\Lib\site-packages\rasa\nlu\registry.py
Thêm dòng: from rasa.nlu.tokenizers.vi_tokenizer import VietnameseTokenizer
            Thêm VietnameseTokenizer vào component_classes


Cài HFTransformersNLP: pip3 install rasa[transformers]

Lưu ý:
- Entity: nên tạo nhiều dạng khác nhau cho từ khóa để RASA nhận diện tốt hơn, tránh huấn luyện chỉ có 1 dạng; nếu ko được nên cài đặt synonym
- Tạo các rule: intent_utter/action để bot so khớp và trả lời liền, tránh để bot chạy bằng TED policy sẽ lâu
